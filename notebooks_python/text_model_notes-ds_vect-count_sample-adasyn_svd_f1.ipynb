{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "Previous notebook drafts have analyzed several classification methods not included here, particularly SVM methods. The SVM classifiers did not return quality results and took long times to run. They are therefore not included in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Parameters\n",
    "\n",
    "* **Data**: Discharge Summary Notes\n",
    "* **Model Imbalance**: ADASYN\n",
    "* **Vectorizor**: Count\n",
    "* **Vectorizor Parameters**: 3000\n",
    "* **Dimension Reduction Method**: Truncated SVD\n",
    "* **Grid Search Scoring Parameter**: f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metric = 'f1'\n",
    "max_features = 3000\n",
    "svd_features = 600\n",
    "max_iter_log = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import feather\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import yellowbrick\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from yellowbrick.text import FreqDistVisualizer\n",
    "from yellowbrick.features import RadViz\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, cross_validate\n",
    "\n",
    "from imblearn.over_sampling import ADASYN \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "# Random State\n",
    "rng = np.random.RandomState(5590)\n",
    "solver_log = 'saga'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Processing\n",
    "## !!!One Data Frame Import Must Be Commented Out!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the dataframes as none for a subsqent check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = None\n",
    "df_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Available Notes\n",
    "#df_all = pd.read_csv('./data/text_processed_all.csv.gz', compression='gzip', low_memory=False)\n",
    "\n",
    "# Dishcharge Summary Notes Onlly\n",
    "df_ds = pd.read_csv('./data/text_processed_discharge_summary.csv.gz', compression='gzip', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do a check to see which data frame we are analyzing, All Notes or Discharge Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_all is not None:\n",
    "    df = df_all\n",
    "else:\n",
    "    df = df_ds\n",
    "      \n",
    "# Convert HADMID to String\n",
    "df.hadm_id = df.hadm_id.astype('int64').astype(str)\n",
    "\n",
    "# Convert Readmit_30 to Int\n",
    "df.readmit_30 = df.readmit_30.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified Tokenizer\n",
    "Define a modified tokenizer function. This function will remove numbers and characters, as well as set all words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_note_events(text):\n",
    "    #create a list of all characters and numbers\n",
    "    num_puct_list = string.punctuation+'0123456789'\n",
    "    \n",
    "    # Create a dictionary aligning each numeric and chcarter to a space\n",
    "    t = str.maketrans(dict.fromkeys(num_puct_list, \" \"))\n",
    "    \n",
    "    # Convert Text to lower case and apply dictionary\n",
    "    text = text.lower().translate(t)\n",
    "    \n",
    "    #tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Stop Words\n",
    "Define custom stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['the','and','to','of','was','with','a','on','in','for','name',\n",
    " 'is','patient','s','he','at','as','or','one','she','his','her','am', \n",
    " 'were','you','pt','pm','by','be','had','your','this','date', 'from',\n",
    " 'there','an','that','p','are','have','has','h','but','o', \n",
    " 'namepattern','which','every','also', 'w', 'd', 'c', 'l', \n",
    " 'q', 'r', 'x', 't', 'm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing Function with Truncated SVD\n",
    "The following function performs all of the prec-processing steps, using sub-sampling to balance the data. The function tokenizes the text using 1-grams and 2-grams. The function returns a processed predictor dataframe for the training and validation data, as well as the target variable for the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing_tr_v(df):\n",
    "    # Clean the Entire Data Set of numbers, characters, carriage returns, and new lines\n",
    "    df.text = df.text.fillna(' ')\n",
    "    df.text = df.text.str.replace('\\n',' ')\n",
    "    df.text = df.text.str.replace('\\r',' ')\n",
    "    \n",
    "    # Split into Train, Valid and Test\n",
    "    ## Shuffle\n",
    "    df = df.sample(n = len(df), random_state = rng)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    ## Extract Data for Test and Valid Sampling\n",
    "    df_v_te = df.sample(frac=0.40, random_state = rng)\n",
    "    \n",
    "    ## Test Sample\n",
    "    df_te = df_v_te.sample(frac = 0.5, random_state = rng)\n",
    "    \n",
    "    ## Valid Sample\n",
    "    df_v = df_v_te.drop(df_te.index)\n",
    "\n",
    "    ## Training Sample\n",
    "    df_tr = df.drop(df_v_te.index)\n",
    "    \n",
    "    # Initialize Vectorizer and SVD\n",
    "    ## Use Modified Tokenizer, Set number of n-grams, use custom stop words\n",
    "    vect = CountVectorizer(max_features = max_features, \n",
    "                           tokenizer = tokenize_note_events, \n",
    "                           ngram_range = (1,2),\n",
    "                           stop_words=stop_words\n",
    "                          )\n",
    "\n",
    "    # Transform Text\n",
    "    # Fit Vectorizer on Training Data\n",
    "    vect.fit(df_tr.text.values)\n",
    "    \n",
    "    # Transform the text into vectors.\n",
    "    x_tr_tf = vect.transform(df_tr.text.values)\n",
    "    x_v_tf = vect.transform(df_v.text.values)\n",
    "    x_te_tf  = vect.transform(df_te.text.values)\n",
    "    \n",
    "    # Define Target Variables\n",
    "    y_tr = df_tr.readmit_30\n",
    "    y_v = df_v.readmit_30\n",
    "    y_te = df_te.readmit_30\n",
    "    \n",
    "    return x_tr_tf, x_v_tf, x_te_tf, y_tr, y_v, y_te, df_tr, vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADASYN Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asadyn_sample(x_train, y_train):\n",
    "     # Initialize ADASYN \n",
    "    ada = ADASYN(random_state = rng)\n",
    "    x_train_adasyn, y_tr_adasym = ada.fit_resample(x_train, y_train)\n",
    "    \n",
    "    return x_train_adasyn, y_tr_adasym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension Reduction: Truncated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_svd(x_tr, x_v, x_te, n_components):\n",
    "    svd = TruncatedSVD(n_components = n_components, random_state = rng)\n",
    "    # Fit SVD on Training Data\n",
    "    svd.fit(x_tr)\n",
    "    \n",
    "    # Transform Sparse Matrices\n",
    "    x_tr_svd = svd.transform(x_tr)\n",
    "    x_v_svd = svd.transform(x_v)\n",
    "    x_te_svd  = svd.transform(x_te)\n",
    "    \n",
    "    return x_tr_svd, x_v_svd, x_te_svd, svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Metrics\n",
    "The following functions calculate the scoring metrics the models will be evlauted on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def calc_prevalence(y_actual):\n",
    "    # calculates prevalence\n",
    "    return sum((y_actual == 1)) /len(y_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Output\n",
    "The following code generates the visual output of the scoring metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(y_tr, y_tr_preds, y_tr_preds_prob, y_v, y_v_preds, y_v_preds_prob):\n",
    "    \n",
    "    fpr_tr, tpr_tr, thresholds_tr = roc_curve(y_tr, y_tr_preds_prob)\n",
    "    fpr_v, tpr_v, thresholds_v = roc_curve(y_v, y_v_preds_prob)\n",
    "\n",
    "    thresh = 0.5\n",
    "\n",
    "    auc_t = '%.3f' %roc_auc_score(y_tr, y_tr_preds_prob)\n",
    "    auc_v = '%.3f' %roc_auc_score(y_v, y_v_preds_prob)\n",
    "    \n",
    "    acc_t = '%.3f' %accuracy_score(y_tr, y_tr_preds)\n",
    "    acc_v = '%.3f' %accuracy_score(y_v, y_v_preds)\n",
    "        \n",
    "    recall_t = '%.3f' %recall_score(y_tr, y_tr_preds)\n",
    "    recall_v = '%.3f' %recall_score(y_v, y_v_preds)\n",
    "        \n",
    "    precision_t = '%.3f' %precision_score(y_tr, y_tr_preds)\n",
    "    precision_v = '%.3f' %precision_score(y_v, y_v_preds)\n",
    "      \n",
    "    \n",
    "    f1_t = '%.3f' %f1_score(y_tr, y_tr_preds)\n",
    "    f1_v = '%.3f' %f1_score(y_v, y_v_preds)\n",
    "    \n",
    "    specificity_t = '%.3f' %calc_specificity(y_tr, y_tr_preds, thresh)\n",
    "    specificity_v = '%.3f' %calc_specificity(y_v, y_v_preds, thresh)\n",
    "    \n",
    "    prevalence_t = '%.3f' %calc_prevalence(y_tr)\n",
    "    prevalence_v = '%.3f' %calc_prevalence(y_v)\n",
    "    \n",
    "    \n",
    "    data = {'Score':['AUC', 'Accuracy', 'Precision', 'Recall', 'F1', 'Specificity', 'Prevalence'],\n",
    "            'Train':[auc_t, acc_t, precision_t, recall_t, f1_t, specificity_t, prevalence_t],\n",
    "            'Validation':[auc_v, acc_v, precision_v, recall_v,  f1_v, specificity_v, prevalence_v]\n",
    "           }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(df)\n",
    "\n",
    "    plt.plot(fpr_tr, tpr_tr,'r-', label = 'Train AUC: %.2f'%roc_auc_score(y_tr, y_tr_preds))\n",
    "    plt.plot(fpr_v, tpr_v,'b-',label = 'Valid AUC: %.2f'%roc_auc_score(y_v, y_v_preds))\n",
    "    plt.plot([0,1],[0,1],'-k')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function trains a default model to the training data and generates training and validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(clf, x_tr, x_v, y_tr, y_v):\n",
    "    \n",
    "    clf.fit(x_tr, y_tr)\n",
    "\n",
    "    y_tr_preds = clf.predict(x_tr)\n",
    "    y_v_preds = clf.predict(x_v)\n",
    "    \n",
    "    y_tr_preds_prob = clf.predict_proba(x_tr)[:,1]\n",
    "    y_v_preds_prob = clf.predict_proba(x_v)[:,1]\n",
    "\n",
    "    model_output(y_tr, y_tr_preds, y_tr_preds_prob, y_v, y_v_preds, y_v_preds_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function runs the gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_opt(x_tr, x_v, y_tr, y_v, clf, hyper_param_dict):\n",
    "\n",
    "    # Create a Grid Search\n",
    "    clf = GridSearchCV(clf, \n",
    "                       hyper_param_dict, \n",
    "                       cv=5, \n",
    "                       verbose=1, \n",
    "                       n_jobs = -1,\n",
    "                       scoring = scoring_metric)\n",
    "\n",
    "    # Best Model\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    \n",
    "    # Export Best Parameters to New Model\n",
    "    clf_best_est = clf.best_estimator_\n",
    "\n",
    "    print(\"Best parameters set found on training set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    return clf_best_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set: Discharge Notes\n",
    "The following analysis will be of the data frame with all discharge notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data is processed and tokenized. This will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1, random_state = rng)\n",
    "x_tr_pre, x_v_pre, x_te_pre, y_tr_pre, y_v_pre, y_te_pre, df_tr_non_xfrm, vect = text_processing_tr_v(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance Data Set Method\n",
    "Use ADASYN Oversampling to Correct the imbalance in the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_adasyn, y_tr_adasyn = asadyn_sample(x_tr_pre, y_tr_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we reduce the dimensions of the sparse matrics to improve model run time.\n",
    "\n",
    "For Discharge Summary, SVD is only used for surveying the default models. For All Notes, SVD is used for final outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_tr_adasyn_svd, x_v_svd, x_te_svd, svd_n = trunc_svd(x_tr_adasyn, x_v_pre, x_te_pre, svd_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of the reduced data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_var = '%.1f' %svd_n.explained_variance_ratio_.sum()\n",
    "print('The explained variance of the Truncatved SVD dimension reduction using', \n",
    "      svd_features,'features is %.3f.' %svd_n.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling - Default Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-SVD\n",
    "Naive Bayes will not run with Truncated SVD due to negative matrix values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define X/Y Values\n",
    "# x_tr = x_tr_adasyn\n",
    "# x_v = x_v_pre\n",
    "# y_tr = y_tr_adasyn\n",
    "# y_v = y_v_pre\n",
    "\n",
    "# train_model(clf, x_tr, x_v, y_tr, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Classifier - Default Settings\n",
    "# clf = LogisticRegression(random_state = rng, solver = solver_log, max_iter = max_iter_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define X/Y Values\n",
    "# x_tr = x_tr_adasyn_svd\n",
    "# x_v = x_v_svd\n",
    "# y_tr = y_tr_adasyn\n",
    "# y_v = y_v_pre\n",
    "\n",
    "# train_model(clf, x_tr, x_v, y_tr, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Classifier - Default Settings\n",
    "# clf = RandomForestClassifier(random_state = rng, n_estimators = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define X/Y Values\n",
    "# x_tr = x_tr_adasyn_svd\n",
    "# x_v = x_v_svd\n",
    "# y_tr = y_tr_adasyn\n",
    "# y_v = y_v_pre\n",
    "\n",
    "# train_model(clf, x_tr, x_v, y_tr, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Classifier - Default Settings\n",
    "# clf = AdaBoostClassifier(random_state = rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tr = x_tr_adasyn_svd\n",
    "# x_v = x_v_svd\n",
    "# y_tr = y_tr_adasyn\n",
    "# y_v = y_v_pre\n",
    "\n",
    "# train_model(clf, x_tr, x_v, y_tr, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Classifier - Default Settings\n",
    "# clf = XGBClassifier(random_state = rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_tr = x_tr_adasyn_svd\n",
    "# x_v = x_v_svd\n",
    "# y_tr = y_tr_adasyn\n",
    "# y_v = y_v_pre\n",
    "\n",
    "# train_model(clf, x_tr, x_v, y_tr, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define X / Y Training and Validation Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x_tr_adasyn\n",
    "x_v = x_v_pre\n",
    "y_tr = y_tr_adasyn\n",
    "y_v = y_v_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes cannot use the dimensionally reduced matrices due to negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "#Define Parameters\n",
    "alpha = np.logspace(1, 5, 4)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_search_opt(x_tr, x_v, y_tr, y_v, clf, hyperparameters)\n",
    "\n",
    "train_model(clf, x_tr, x_v, y_tr, y_v)\n",
    "\n",
    "# Define for Test Analysis\n",
    "clf_nb_opt = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "#Define Parameters\n",
    "n_neighbors  = np.linspace(3,33,11).astype('int') \n",
    "weights = ('uniform', 'distance')\n",
    "metric = ('euclidean', 'manhattan')\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(n_neighbors = n_neighbors, weights = weights, metric = metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_search_opt(x_tr, x_v, y_tr, y_v, clf, hyperparameters)\n",
    "\n",
    "train_model(clf, x_tr, x_v, y_tr, y_v)\n",
    "\n",
    "# Define for Test Analysis\n",
    "clf_knn_opt = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Classifier\n",
    "clf = LogisticRegression(random_state = rng, solver = solver_log, max_iter = max_iter_log)\n",
    "\n",
    "#Define Parameters\n",
    "penalty = ['l1','l2']       \n",
    "C = np.logspace(-5, 1, 7)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty = penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_search_opt(x_tr, x_v, y_tr, y_v, clf, hyperparameters)\n",
    "\n",
    "train_model(clf, x_tr, x_v, y_tr, y_v)\n",
    "\n",
    "# Define for Test Analysis\n",
    "clf_logreg_opt = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest models have so far performed so-so, and have taken a very long time to run. For the training data it often overfits to match 100%. I recommend commenting out these models until final analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Establish Classifier\n",
    "# clf = RandomForestClassifier(random_state = rng)\n",
    "\n",
    "# #Define Parameters\n",
    "# n_estimators = [100, 300, 500, 800, 1200]\n",
    "# max_depth = [5, 8, 15, 25, 30]\n",
    "# min_samples_split = [2, 5, 10, 15, 100]\n",
    "# min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "\n",
    "# # Create hyperparameter options\n",
    "# hyperparameters = dict(n_estimators=n_estimators, \n",
    "#                        max_depth=max_depth,\n",
    "#                        min_samples_split = min_samples_split,\n",
    "#                        min_samples_leaf = min_samples_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = grid_search_opt(x_tr, x_v, clf, hyperparameters)\n",
    "\n",
    "# train_model(clf, x_tr, x_v)\n",
    "\n",
    "# # Define for Test Analysis\n",
    "# clf_rf_opt_pre = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Classifier\n",
    "clf = AdaBoostClassifier(random_state = rng)\n",
    "\n",
    "#Define Parameters\n",
    "n_estimators = [50, 100, 150, 200, 250]\n",
    "learning_rate = np.logspace(-4, 2, 7)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(n_estimators=n_estimators, \n",
    "                       learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_search_opt(x_tr, x_v, y_tr, y_v, clf, hyperparameters)\n",
    "\n",
    "train_model(clf, x_tr, x_v, y_tr, y_v)\n",
    "\n",
    "# Define for Test Analysis\n",
    "clf_ada_opt = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Function Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Classifier\n",
    "clf = XGBClassifier(random_state = 5590)\n",
    "\n",
    "#Define Parameters\n",
    "n_estimators = [25, 50, 100, 150, 200]\n",
    "learning_rate = np.logspace(-4, 1, 6)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(n_estimators=n_estimators, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid_search_opt(x_tr, x_v, y_tr, y_v, clf, hyperparameters)\n",
    "\n",
    "train_model(clf, x_tr, x_v, y_tr, y_v)\n",
    "\n",
    "# Define for Test Analysis\n",
    "clf_xbg_opt = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define X/Y Values\n",
    "For Naive Bayes, the pre-svd values will be used and insert manually. Global values for x and y will be defined here for the remaining models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_te_pre\n",
    "y = y_te_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_cm(y_pred, y_truth, labels):\n",
    "    '''\n",
    "    'Pretty' implementation of a confusion matrix with some evaluation statistics.\n",
    "    \n",
    "    Input:\n",
    "    y_pred - object with class predictions from the model\n",
    "    y_truth - object with actual classes\n",
    "    labels - list containing label names\n",
    "    '''\n",
    "    \n",
    "    cm = confusion_matrix(y_truth, y_pred)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, square = True, cmap = 'BuGn_r')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    ax.set_ylabel('Actual label')\n",
    "    ax.set_title('Confusion Matrix', size = 15) \n",
    "    ax.xaxis.set_ticklabels(labels)\n",
    "    ax.yaxis.set_ticklabels(labels)\n",
    "    \n",
    "    print('#######################')\n",
    "    print('Evaluation metrics ####')\n",
    "    print('#######################')\n",
    "    print('Accuracy: {:.3f}'.format(accuracy_score(y_truth, y_pred)))\n",
    "    print('AUC Score: {:.3f}'.format(roc_auc_score(y_truth, y_pred)))\n",
    "    print('Precision: {:.3f}'.format(precision_score(y_truth, y_pred)))\n",
    "    print('Recall: {:.3f}'.format(recall_score(y_truth, y_pred)))\n",
    "    print('F1: {:.3f}'.format(f1_score(y_truth, y_pred)))\n",
    "    print('Prevelance: {:.3f}'.format(calc_prevalence(y_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_score_cv(clf, x, y):\n",
    "    scoring = ['roc_auc', 'accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    results = cross_validate(estimator = clf,\n",
    "                                          X = x,\n",
    "                                          y = y,\n",
    "                                          cv = 5,\n",
    "                                          scoring = scoring)\n",
    "    for metric_name in results.keys():\n",
    "        average_score = np.average(results[metric_name])\n",
    "        print('%s : %.3f' % (metric_name, average_score))\n",
    "    \n",
    "    prevalence_te = '%.3f' %calc_prevalence(y)\n",
    "    print('positive target prevalence: ', prevalence_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf_nb_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_te_pre, clf.predict(x_te_pre)\n",
    "pretty_cm(y_pred, y_true, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_cv(clf, x_te_pre, y_te_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf_knn_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y, clf.predict(x)\n",
    "pretty_cm(y_pred, y_true, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_cv(clf, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf_logreg_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y, clf.predict(x)\n",
    "pretty_cm(y_pred, y_true, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_cv(clf, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf_ada_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y, clf.predict(x)\n",
    "pretty_cm(y_pred, y_true, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_cv(clf, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf_xbg_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y, clf.predict(x)\n",
    "pretty_cm(y_pred, y_true, [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_score_cv(clf, x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
